--- dpif-netdev.c	2018-02-03 11:25:14.995180355 +0800
+++ dpif-netdev-new.c	2018-02-03 11:31:46.643176712 +0800
@@ -70,6 +70,12 @@
 #include "util.h"
 #include "openvswitch/vlog.h"
 
+// Sigcomm: add ringbuffer header
+#include "ringbuffer.h"
+#include "tuple.h"
+#include <rte_ip.h>
+// end
+
 VLOG_DEFINE_THIS_MODULE(dpif_netdev);
 
 #define FLOW_DUMP_MAX_BATCH 50
@@ -448,6 +454,12 @@
      * reporting to the user */
     unsigned long long stats_zero[DP_N_STATS];
     uint64_t cycles_zero[PMD_N_CYCLES];
+
+    // SIGCOMM: add ringbuffer
+#ifdef SIGCOMM_MEASUREMENT
+    ringbuffer_t * rb;
+#endif
+    // SIGCOMM: end
 };
 
 #define PMD_INITIAL_SEQ 1
@@ -509,6 +521,98 @@
 static inline bool emc_entry_alive(struct emc_entry *ce);
 static void emc_clear_entry(struct emc_entry *ce);
 
+// SIGCOMM: add ringbuffer function
+ringbuffer_t* create_ringbuffer_shm(const char* name, uint64_t tuple_size) {
+
+    LOG_MSG("This is a normal ringbuffer\n");
+
+    // allocate ringbuffer_t*
+    ringbuffer_t* ret = (ringbuffer_t*)malloc(sizeof(struct RingBuffer));
+    if (ret == NULL) {
+        LOG_ERR("ringbuffer_t* malloc() failed: %s\n", strerror(errno));
+    }
+
+    // setup name, fd, tuple size
+    ret->name = (char*)malloc(strlen(name) + 1);
+    if (ret == NULL) {
+        LOG_ERR("ringbuffer_t* name malloc() failed: %s\n", strerror(errno));
+    }
+    strcpy(ret->name, name);
+    ret->name[strlen(name)] = 0;
+    ret->fd = -1;
+    ret->tuple_size = tuple_size;
+    
+    // create shared memory device
+    int shm_fd = -1;
+    shm_unlink(name);
+    shm_fd = shm_open(name, O_RDWR | O_CREAT | O_EXCL, S_IRUSR | S_IWUSR);
+    if (shm_fd == -1) {
+        LOG_ERR("shm_open() failed: %s\n", strerror(errno));
+    }
+    
+    // set shared memory size
+    uint64_t shared_size = sizeof(sem_t) + sizeof(struct RBMeta) + sizeof(struct RBAppro) + RB_SIZE * tuple_size;
+    if (ftruncate(shm_fd, shared_size) == -1) {
+        shm_unlink(name);
+        LOG_ERR("ftruncate() failed: %s\n", strerror(errno));
+    }
+    
+    // map into our space
+    void* ptr = mmap(0, shared_size, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0);
+    if (ptr == MAP_FAILED) {
+        shm_unlink(name);
+        LOG_ERR("mmap() failed: %s\n", strerror(errno));
+    }
+
+    // set up pointers to the shared memory region
+    ret->meta = (struct RBMeta*)((unsigned char*)ptr + sizeof(sem_t));
+    ret->appro = (struct RBAppro*)((unsigned char*)ptr + sizeof(sem_t) + sizeof(struct RBMeta));
+    ret->data = (unsigned char*)ptr + sizeof(sem_t) + sizeof(struct RBMeta) + sizeof(struct RBAppro);
+    
+    // init ring buffer, require lock the resouces
+    sem_t* sem = (sem_t*) ptr;
+    if (sem_init(sem, 1, 0) == -1) {
+        shm_unlink(name);
+        LOG_ERR("sem_init() failed: %s\n", strerror(errno));
+    }
+    
+    memset(ret->appro, 0, sizeof(struct RBAppro));
+    ret->meta->readIndex = 0; 
+    ret->meta->writeIndex = 0;
+    ret->meta->localWriteIndex = 0;
+    ret->meta->nextReadIndex = 0;
+    ret->meta->rBatchCount = 0;
+    ret->meta->localReadIndex = 0;
+    ret->meta->nextWriteIndex = 0;
+    ret->meta->wBatchCount = 0;
+    memset(ret->data, 0, RB_SIZE * tuple_size);
+    
+    // compelte init
+    sem_post(sem);
+    
+    return ret;
+}
+
+// 0: success; otherwise: fail
+int write_ringbuffer(ringbuffer_t* rb, void* data, unsigned long size) {
+    int afterNextWriteIndex = nextVal(rb->meta->nextWriteIndex);
+    if (afterNextWriteIndex == rb->meta->localReadIndex) {
+        if (afterNextWriteIndex == rb->meta->readIndex) {
+            return -1;
+        }
+        rb->meta->localReadIndex = rb->meta->readIndex;
+    }
+    memcpy(rb->data+rb->tuple_size*rb->meta->nextWriteIndex, data, size);
+    rb->meta->nextWriteIndex = afterNextWriteIndex;
+    rb->meta->wBatchCount++;
+    if (rb->meta->wBatchCount >= RB_BATCH) {
+        rb->meta->writeIndex = rb->meta->nextWriteIndex;
+        rb->meta->wBatchCount = 0;
+    }
+    return 0;
+}
+// SIGCOMM: end
+
 static void
 emc_cache_init(struct emc_cache *flow_cache)
 {
@@ -2895,6 +2999,15 @@
     }
     cmap_insert(&dp->poll_threads, CONST_CAST(struct cmap_node *, &pmd->node),
                 hash_int(core_id, 0));
+    
+
+    // SIGCOMM: add ringbuffer setting
+#ifdef SIGCOMM_MEASUREMENT
+    char name[30];
+    sprintf(name, "/rb_%d", core_id == NON_PMD_CORE_ID ? 0 : index + 1);
+    pmd->rb = create_ringbuffer_shm(name , sizeof(tuple_t));
+    VLOG_ERR("%s initialized.", name);
+#endif
 }
 
 static void
@@ -3377,6 +3490,24 @@
     for (i = 0; i < cnt; i++) {
         struct dp_netdev_flow *flow;
 
+// SIGCOMM: write to ringbuffer
+#ifdef SIGCOMM_MEASUREMENT
+        struct rte_mbuf * mbuf= &(packets[i]->mbuf);
+
+        if (likely(mbuf != NULL)) {  
+            struct ether_hdr *eth_hdr;
+            eth_hdr = rte_pktmbuf_mtod(mbuf, struct ether_hdr *);
+            if (eth_hdr->ether_type == rte_cpu_to_be_16(ETHER_TYPE_IPv4)) {
+                struct ipv4_hdr *ip_hdr;
+                tuple_t tuple;
+                ip_hdr = rte_pktmbuf_mtod(mbuf, struct ipv4_hdr *);
+                tuple.key.src_ip = ip_hdr->src_addr;
+                tuple.key.dst_ip = ip_hdr->dst_addr;
+                while (write_ringbuffer(pmd->rb, (void*)&tuple, sizeof(tuple_t)) != 0);
+            }
+        }
+#endif
+
         if (OVS_UNLIKELY(dp_packet_size(packets[i]) < ETH_HEADER_LEN)) {
             dp_packet_delete(packets[i]);
             continue;
